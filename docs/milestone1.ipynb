{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "milestone1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tYJmdaj1iiC",
        "colab_type": "text"
      },
      "source": [
        "# CS207 Final Project: Milestone 1 - October 29 2019\n",
        "Geng Yichen, Jian Yingsi, Meeus Matthieu, Zhang Lihong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKmny9UOYz2W",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cBVisQoENuI",
        "colab_type": "text"
      },
      "source": [
        "Derivatives come up in every aspect of science and engineering. Calculus taught us how to derive analytical expressions of functional derivatives, but in many cases this is either impossible or too much of a hassle. Therefore, numerical methods or algorithmic approaches to compute the derivative are extremely important. \n",
        "Methods of computing functions' derivatives in computer programs can be classified into 4 types: \n",
        "\n",
        "(1) Determining derivatives by hands and coding them. <br/>\n",
        "(2) Symbolic differentiation in computer tools, such as Mathematica and Maple. <br/>\n",
        "(3) Numerical methods: using finite differences to approxiate derivatives. <br/>\n",
        "(4) Automatic Differentiation, which is the subject of our project. <br/>\n",
        "\n",
        "Automatic differentiation (AD) is a set of techniques for evaluating functional derivatives efficiently and accurately in computer programs. For any analytic function f(x) to be differentiated at a point $x_0$, AD first rewrites f(x) as a combination of elementary functions, then determining the derivative values of f(x) through combining derivatives of elementary functions by the chain rule. Since the derivative values of all elementary functions are known and accurate, and the procedures of AD have no potential sources of errors except tiny rounding errors due to machine precision, thus the derivative values obtained by AD are accurate. As for other differentiation methods, manual calculating functional derivatives and coding them by hands can be tedious, time-consuming and prone to make mistakes; symbolic differentiation could return rigmarole and unreadable symbolic expressions; and numerical method of finite differences could be ill-conditioned due to truncation and round-off errors, and is also inappropriate to handle functional derivatives with many independent variables. \n",
        "\n",
        "For example, in the numerical method of finite difference, the derivative is calculated as the following where the limit for h is approached but not put to zero:\n",
        "\n",
        "$$\\frac{df}{dx} \\approx \\frac{f(x+h) - f(x)}{h}$$\n",
        "\n",
        "While this approach yields decent results in many cases, it is never completely accurate. For too large values of h, the error originates from the intrinsic error of the finite difference derivative. For too small values of h, the error originates from rounding errors. \n",
        "\n",
        "Although AD does not show explicit derivative expressions, people usually only want to obtain derivative values at some points rather than symbolic expressions, thus AD is much better than other differentiation methods with respect to determining functional derivative values.\n",
        "\n",
        "In modern differentiation computation, AD is the most efficient and accurate tool to implement differentiation in computer programs. In this project, we will design an accurate, user-oriented differentiation calculator by implementing AD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-0jo3nlx-_G",
        "colab_type": "text"
      },
      "source": [
        "# Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwWhNMOfyFh1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Automatic differentiation is an algorithmic approach to compute derivatives up until machine precision accuracy. It has two common methods: forward and reverse mode. In this project, only the forward mode will be discussed at first. Forward automatic differentiation leverages the chain rule to split the differentiation of a complex function in elementary functions and makes use of the easy derivatives of elementary functions.  If $h(u(t))$ is the function of which the derivative is required, the chain rule for partial derivatives says:\n",
        "\n",
        "$$\\frac{\\partial h}{\\partial t} = \\frac{\\partial h}{\\partial u}*\\frac{\\partial u}{\\partial t}$$\n",
        "\n",
        "Or for $h(u(t), v(t))$:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\frac{\\partial h}{\\partial t} = \\frac{\\partial h}{\\partial u}*\\frac{\\partial u}{\\partial t} + \\frac{\\partial h}{\\partial v}*\\frac{\\partial v}{\\partial t}\n",
        "\\end{equation}\n",
        "\n",
        "Hence, the computation of the derivatives of complicated functions that consist of multiple, consequent elementary operations can be split into the multiplication and addition of derivatives of the elementary functions in the following table. Examples of the elementary operations are addition and multiplication but also sine, cosine and log. The complete list of elementary functions that will be incorporated in this package can be found in 'Implementation'. A subset is illustrated in the table below:\n",
        "\n",
        "| Elementary function        | Example | \n",
        "| :-------------: |:-------------:|\n",
        "| Field Operations    | $+ - * / $ |\n",
        "| Powers     |$x^2, x^6$|\n",
        "| Roots     |$\\sqrt{x}$|\n",
        "| Trigonometric     |$sin(x)$|\n",
        "| Inverse Trigonometric     |$asin(x)$|\n",
        "| Logaritmic     |$log(x)$|\n",
        "| Exponential    |$e^x$|\n",
        "\n",
        "The split of the complex function into its elementary operations is commonly visualized in a so-called computational graph. This summarizes the sequence of operations that need to be done for the evaluation and differentiation of the function. An example for the simple function $f(x,y) = xy + exp(xy) $ is given in the image below. Note that this example comes from Lecture 12.\n",
        "\n",
        "![alt text](https://github.com/BackPropagators/cs207-FinalProject/raw/master/Docs/Images/CompGraph.png \"Computational Graph\")\n",
        "\n",
        "For functions in higher dimensions h(x): ${\\rm I\\!R}^m \\rightarrow {\\rm I\\!R}^n$, the entire Jacobian will be computed using the same, simple approach. Recall the definition of the Jacobian J in ${\\rm I\\!R}^{nxm}$ for function h(x):\n",
        "\n",
        "$$\\mathbf{J}=\\left[\\begin{array}{cccc}\n",
        "\\frac{\\partial h_1}{\\partial x_1} & \\frac{\\partial h_1}{\\partial x_2} & .. & \\frac{\\partial h_1}{\\partial x_m} \\\\\n",
        "\\frac{\\partial h_2}{\\partial x_1} & \\frac{\\partial h_2}{\\partial x_2} & .. & \\frac{\\partial h_2}{\\partial x_m} \\\\\n",
        ".. & .. & .. & .. \\\\\n",
        "\\frac{\\partial h_n}{\\partial x_1} & \\frac{\\partial h_n}{\\partial x_2} & .. & \\frac{\\partial h_n}{\\partial x_m}\n",
        "\\end{array}\\right]$$\n",
        "\n",
        "Note that in many cases the gradient of h with respect to an input variable $x_i$ is required. For $x_i$ this will correspond to the i-th column of the Jacobian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeyiZBf-4AHU",
        "colab_type": "text"
      },
      "source": [
        "# How to Use AutoDiff\n",
        "\n",
        "To use the package, users need to use pip to install the package and then import it. \n",
        "\n",
        "```python\n",
        ">>> from AutoDiff.ForwardAd import Var\n",
        ">>> import numpy as np\n",
        ">>> x = Var(np.array([2.0]), np.array([1, 0]))\n",
        ">>> y = Var(np.array([3.0]), np.array([0, 1]))\n",
        ">>> f = x*y\n",
        ">>> f.val\n",
        "array([6.])\n",
        ">>> f.jacobian\n",
        "array([3., 2.])\n",
        "```\n",
        "\n",
        "# Software Organization\n",
        "\n",
        "\n",
        "**Porject Directory Structure**\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "                    CS207-FinalProject/\n",
        "                                       README.md\n",
        "                                       LICENSE\n",
        "                                       setup.py\n",
        "                                       AutoDiff/\n",
        "                                                _init_.py\n",
        "                                                ForwardAD.py\n",
        "                                       Documentation/\n",
        "                                                     milestone1.ipynb\n",
        "                                       Test/\n",
        "                                            test_suite.py\n",
        "                                       Demo/\n",
        "                                            presentation.pdf\n",
        "                                       ...\n",
        "                   \n",
        "                           \n",
        "**Included Modules and Basic Functionality**\n",
        "\n",
        "NumPy: A general-purpose array-processing package. It provides a high-performance multidimensional array object, and tools for working with these arrays. For details, see https://numpy.org\n",
        "\n",
        "pytest: A software test framework, which is a command-line tool that automatically finds written tests, runs the tests, and reports the results. For details, see https://docs.pytest.org/en/latest/\n",
        "\n",
        "Setuptools: A fully-featured, actively-maintained, and stable library designed to facilitate packaging Python projects. \n",
        "For details, see https://setuptools.readthedocs.io/en/latest/\n",
        "\n",
        "doctest: This module searches for pieces of text (usually in the documentation part) that look like interactive Python sessions, and then executes those sessions to verify that they work exactly as shown. For details, see https://docs.python.org/3/library/doctest.html\n",
        "\n",
        "\n",
        "**Test**\n",
        "\n",
        "The test suites live in *CS207-FinalProject/Test/* folder.  We will use Travis CI to run tests and use CodeCov to automatically checks code coverage. \n",
        "\n",
        "\n",
        "**Distributing Our Package**\n",
        "\n",
        "We will use PyPI to distribute our package. The Python Package Index (PyPI) is a repository of software for the Python programming language.\n",
        "\n",
        "\n",
        "**Packaging**\n",
        "\n",
        "We will follow the Python Packaging User Guide published by the Python Packaging Authority(PyPA), which is the authoritative resource on how to package, publish, and install Python projects using current tools. We will use Setuptools because it is comprehensive, actively-maintained, and stable to  create an package for easy distibution out of our project.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypeCT0O3UHqw",
        "colab_type": "text"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5tzv61IUOXV",
        "colab_type": "text"
      },
      "source": [
        "**Core Data Structures**\\\n",
        "The core data structure is `numpy.array`.\n",
        "\n",
        "**Classes to be Implemented?**\\\n",
        "Inside the `ForwardAD.py`, we will implement the `Var` class.\n",
        "\n",
        "**Method and Name Attributes of Classes**\\\n",
        "The `Var` class has two attributes: `self.val`, which stores the value of the current function and `self.jacobian`, which is represented by a `numpy.array` and stores the function's partial derivatives. We will overload operators by dunder methods, including `__add__`, `__sub__`, `__mul__`, `__truediv__`,  `__pow__` and define exponential, logarithmic, square root and trignometric functions. The following is an example of what the structure of `Var` class will look like. We temporarily use `pass` in the content of each method, and we will replace them by the real codes in the following process.\n",
        "\n",
        "```python\n",
        "class Var:\n",
        "    def __init__(self, a, j):\n",
        "        self.val = a\n",
        "        self.jacobian = j\n",
        "    \n",
        "    def __add__(self, other):\n",
        "      pass\n",
        "    \n",
        "    def __sub__(self, other):\n",
        "      pass\n",
        "    \n",
        "    def __mul__(self, other):\n",
        "      pass\n",
        "    \n",
        "    def __truediv__(self, other):\n",
        "      pass\n",
        "    \n",
        "    def __pow__(self, other):\n",
        "      pass\n",
        "    \n",
        "    def exp(self):\n",
        "      pass\n",
        "    \n",
        "    def log(self):\n",
        "      pass\n",
        "    \n",
        "    def sqrt(self):\n",
        "      pass\n",
        "    \n",
        "    def sin(self):\n",
        "      pass\n",
        "    \n",
        "    def cos(self):\n",
        "      pass\n",
        "\n",
        "    def tan(self):\n",
        "      pass\n",
        "```\n",
        "\n",
        "**External Dependencies**\\\n",
        "We will rely on the `NumPy` package.\n",
        "\n",
        "**Dealing with Elementary Functions**\\\n",
        "We will define methods that represent these elementary functions inside the `Var` class (see the example above). When calling these functions, we can simply use `Var.function_name`. For example,\n",
        "\n",
        "```python\n",
        ">>> x = Var(np.array([4.0]), np.array([1]))\n",
        ">>> f = Var.sqrt(x)\n",
        ">>> f.val\n",
        "array([2.])\n",
        ">>> f.jacobian\n",
        "array([0.25])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHGmIuzBV3aF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}